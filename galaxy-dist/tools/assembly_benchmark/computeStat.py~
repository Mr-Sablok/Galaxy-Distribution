#!/usr/bin/python
import compareStatGraph as csg, fileManipulation as fmp, sys, os, numpy as np
from pyPdf import PdfFileWriter, PdfFileReader

refPath = os.getcwd().split("galaxy-dist")[0]+ "galaxy-dist/tools/assembly_benchmark/reference/refGen/"
genePath = os.getcwd().split("galaxy-dist")[0]+ "galaxy-dist/tools/assembly_benchmark/reference/genefiles/" 
builtInRef = {'A_hydrophila_ATCC_7966':refPath+'A_hydrophila_ATCC_7966.fna',
	      'A_hydrophila_ATCC_7966G':genePath+'A_hydrophila_ATCC_7966.gff',
	      'B_cereus_ATCC_1098':refPath+'B_cereus_ATCC_1098.fna',
	      'B_cereus_ATCC_1098G':genePath+'B_cereus_ATCC_1098.gff',
	      'B_fragilis_638R':refPath+'B_fragilis_638R.fna',
	      'B_fragilis_638RG':genePath+'B_fragilis_638R.gff',
	      'M_abscessus_ATCC_19977':refPath+'M_abscessus_ATCC_19977.fna',
	      'M_abscessus_ATCC_19977G':genePath+'M_abscessus_ATCC_19977.gff',
	      'R_sphaeroides_2-4-1':refPath+'R_sphaeroides_2-4-1.fna',
	      'R_sphaeroides_2-4-1G':genePath+'R_sphaeroides_2-4-1.gff',
	      'S_aureus_USA300_TCH151':refPath+'S_aureus_USA300_TCH151.fna',
	      'S_aureus_USA300_TCH151G':genePath+'S_aureus_USA300_TCH151.gff',
	      'V_cholerae_O1_biovar_eltor_str_N1696':refPath+'V_cholerae_O1_biovar_eltor_str_N1696.fna',
	      'V_cholerae_O1_biovar_eltor_str_N1696G':genePath+'V_cholerae_O1_biovar_eltor_str_N1696.gff',
	      'X_axonopodis_pv_citrumel':refPath+'X_axonopodis_pv_citrumel.fna',
	      'X_axonopodis_pv_citrumelG':genePath+'X_axonopodis_pv_citrumel.gff'
	}

prefix = os.getcwd().split("galaxy-dist")[0]+"galaxy-dist/static/stat/"
history = [] #History element with previous run
contigLabel = [] #Labels for contig files
scaffoldLabel = [] #Labels for scaffold files
contig = [] #Input contig files
scaffold = [] #Input scaffold files
ref = '' #Uploaded reference genome
dbRef = [] #Builtin reference genome
multi = False #If uploaded ref is multiple files in one or not
minThreshold = 0;
maxThreshold = 1000;
threads = 0 #Nr of threads 
html_file = ''
path = ''

def runCommand(customPath, reference, gene, labels, files, filetype):
	oscommand = os.getcwd().split("galaxy-dist")[0]+ "galaxy-dist/tools/assembly_benchmark/quast/quast.py "
	os.system('mkdir '+customPath) 
	oscommand += '-o '+customPath
		
	if reference != '':
		oscommand += ' -R ' + reference
		if gene != '':
			oscommand += ' -G ' + gene
	
	lbl = ''
	if len(labels) != 0:
		lbl = ' -l "'
		for l in labels:
			lbl += l+', '
		lbl = lbl[0:len(lbl)-2]+'"'
		oscommand += lbl
	if ((minThreshold != 0) | ( maxThreshold != 1000)):
	    oscommand += ' -t '+minThreshold+','+maxThreshold
	if filetype:
	   oscommand += ' --scaffolds'
	if threads != 0:
	    oscommand += ' -T '+threads
	    
	dataset = ''
	for f in files:
		dataset += ' '+f
	oscommand += dataset

	#Run command
	os.system(oscommand)

def writeHtmlFile(path):
	#Process result, add xy-plot functionality and assessment
	result = open('result.html', 'w')
	result.write('<!DOCTYPE html>\n')
	result.write('<html lang="en">\n')
	result.write('  <head></head>\n')
	result.write('  <body>\n')
	result.write('    <a name="top"><h1>Assembly Benchmark</h1></a>\n')
	result.write('    <p><h2>Content</h2>\n')
	result.write('    <dl>\n')
	for pl in [d for d in sorted(os.listdir(path), key=str.lower) if os.path.isdir(path+'/'+d)]:
		#Make scroll-links
		result.write('    <dt><a href="#'+pl+'"><strong><font color="black">'+pl+'</font></strong></a></dt>\n<dd>')
		for p in [d for d in sorted(os.listdir(path+'/'+pl), key=str.lower) if os.path.isdir(path+'/'+pl+'/'+d)]:
			if p.strip() != 'report_html_aux':
				result.write('    <a href="#'+pl+'-'+p+'"><font color="black">'+p+'</font></a><br>\n')
		result.write('    </dd><br>\n')
	result.write('    </dl>\n')
	for pathlist in [d for d in sorted(os.listdir(path), key=str.lower) if os.path.isdir(path+'/'+d)]:
		path += '/'+pathlist
		oldReport = open(path+'/report.html', 'r')
		newReport = open(path+'/newReport.html', 'w')
	
	        #Add plot file
		plot = os.getcwd().split("galaxy-dist")[0]+ "galaxy-dist/tools/assembly_benchmark/draw_custom_plot.js"
		os.system('cp '+plot+' '+path+'/report_html_aux/scripts/')
			
		#Add own modifications
		for line in oldReport:
			if line.strip() == '<head>':
				newReport.write(line+csg.getScript())
			elif 'id=\'subheader\'' not in line:
				newReport.write(line)
			else:
				newReport.write(line+csg.assessOutput(path+'/json/report.json'))
		oldReport.close()
		newReport.close()
		
	        #Replace reportfile
		os.system('mv '+path+'/newReport.html '+path+'/report.html')
			
	        #Show result
		#result.write('    <hr>\n')
		result.write('    <hr>\n<a name="'+pathlist+'"><h3>'+pathlist+'</h3></a><ul>\n')
		for filename in [f for f in sorted(os.listdir(path), key=str.lower) if os.path.isfile(path+'/'+f)]:
			result.write('    <li><a href="'+pathlist+'/'+filename+'">'+filename+'</a><br>\n')
		result.write('    </ul></p>\n')
		#Add all the other folders
		for p in [d for d in sorted(os.listdir(path), key=str.lower) if os.path.isdir(path+'/'+d)]:
			if p.strip() != 'report_html_aux':
				result.write('   <p><a name="'+pathlist+'-'+p+'"><strong>'+p+'</strong></a><ul>\n')
				for filename in [f for f in sorted(os.listdir(path+'/'+p), key=str.lower) if os.path.isfile(path+'/'+p+'/'+f)]:
					result.write('    <li><a href="'+pathlist+'/'+p+'/'+filename+'">'+filename+'</a><br>\n')
				result.write('    </ul></p>\n')
		result.write('    <a href="#top"><font color="black">[To the top]</font></a><br>')	
	        #Get original path
		path = path[:-len(pathlist)-1]
	result.write('    </body>\n')
	result.write('</html>')
	result.close()

def getLongestDelimiter(inputFile, key, header):
	delimiter = 0
	for line in inputFile:
		if k in key:
			if line.startswith(k.strip()):
				content = line.split(k.strip())[-1].strip()
				if delimiter < len(content):
					delimiter = len(content)
				break
		#if (((line.startswith('# gene')) | (line.startswith('# unaligned'))) & (delimiter < len(' '.join(line.split(key)[-1])))):
		#	delimiter = len(' '.join(line.split(key)[-1]))
		#elif delimiter < line.split(' ')[-1]:
		#	delimiter = len(line.split(' ')[-1])
	if delimiter < len(header):
		delimiter = len(header)
	return delimiter+4
def combineResult(path1, path2, path3, header):
	#os.system('cp -rf '+path2+'/report_html_aux '+path3)
	#os.system('cp '+path2+'/*report* '+path3)
	#os.system('mkdir '+path3+'/json')
	#os.system('cp -rf '+path2+'/json '+path3)
	#Combine plot in main folder
	output = PdfFileWriter()
	input1 = PdfFileReader(file(path1+'/plots.pdf', "rb"))
	input2 = PdfFileReader(file(path2+'/plots.pdf', "rb"))

	for page in range(0, input1.getNumPages()):
		output.addPage(input1.getPage(page))
	for page in range(0, input2.getNumPages()):
		output.addPage(input2.getPage(page))
	outputStream = file(path3+'/tmp.pdf', 'wb')
	output.write(outputStream)
	outputStream.close()
	#Change name of pdf file
	os.system('mv '+path3+'/tmp.pdf '+path3+'/plots.pdf')
	#Combine txt files
	element = [#'Assembly                     ',
		   '# contigs (>= 0 bp)          ',
		   '# contigs (>= 1000 bp)       ',
		   'Total length (>= 0 bp)       ',
		   'Total length (>= 1000 bp)    ',
		   '# contigs                    ',
		   'Total length                 ',
		   'Largest contig               ',
		   'Reference length             ',
		   'GC (%)                       ',
		   'Reference GC (%)             ',
		   'N50                          ',
		   'NG50                         ',
		   'N75                          ',
		   'NG75                         ',
		   'L50                          ',
		   'LG50                         ',
		   'L75                          ',
		   'LG75                         ',
		   '# misassemblies              ',
		   'Misassembled contigs length  ',
		   '# local misassemblies        ',
		   '# unaligned contigs          ',
		   'Unaligned contigs length     ',
		   'Genome fraction (%)          ',
		   'Duplication ratio            ',
		   '# N\'s per 100 kbp            ',
		   '# mismatches per 100 kbp     ',
		   '# indels per 100 kbp         ',
		   '# genes                      ',
		   'Largest alignment            ',
		   'NA50                         ',
		   'NGA50                        ',
		   'NA75                         ',
		   'NGA75                        ',
		   'LA50                         ',
		   'LGA50                        ',
		   'LA75                         ',
		   'LGA75                        '
		   ]
	output = open(path3+'/tmp.txt','w')
	input1 = open(path1+'/report.txt','r').readlines()
	input2 = open(path2+'/report.txt','r').readlines()
	
	#Add headings
	output.write(''.join(input1[0:2]))
	delimiter = ''
	longestDel = 0
	if not header:
		longestDel = getLongestDelimiter(input1, element, path1.split('/')[-1])
		for i in range(longestDel-len(path1.split('/')[-1])): delimiter += ' '
		output.write('Assembly                     '+path1.split('/')[-1]+delimiter+path2.split('/')[-1]+'\n')
	else:
		longestDel = getLongestDelimiter(input1, element, input1[2].split('Assembly')[-1].strip())
		for i in range(longestDel-len(input1[2].split('Assembly')[-1].strip())): delimiter += ' '
		output.write('Assembly                     '+input1[2].split('Assembly')[-1].strip()+delimiter+path2.split('/')[-1]+'\n')
	#Merge content
	for e in element:
		xInput = '-'
		yInput = '-'
		for x in input1:
			#x = x.strip()
			if x.startswith(e.strip()+'  '):
				xInput = x.split(e.strip())[-1].strip()
				#if x.split(' ')[-1] == 'part':
				#	xInput = ' '.join(x.split(' ')[-4:])
				#else:
				#	xInput = x.split(' ')[-1]
				break
		for y in input2:
			#y = y.strip()
			if y.startswith(e.strip()+'  '):
				yInput = y.split(e.strip())[-1].strip()
				#if y.split(' ')[-1] == 'part':
				#	yInput = ' '.join(y.split(' ')[-4:])
				#else:
				#	yInput = y.split(' ')[-1]
				break
	
		if (xInput == '-') & (yInput == '-'):
			break
		else:
			delimiter = ''
			for i in range(longestDel-len(xInput)):
				delimiter += ' '
			output.write(e+xInput+delimiter+yInput+'\n')
	output.close()
	
	#Change name of result file
	os.system('mv '+path3+'/tmp.txt '+path3+'/report.txt')
	
	#Tranposition
	transpose = []
	output = open(path3+'/transposed_report.txt','w')
	input1 = open(path3+'/report.txt','r').readlines()
	output.write('\n'.join(input1[0:2]))
	element.append('Assembly    ')
	space = []
	for line in input1:
		for e in element:
			if line.startswith(e.strip()+'  '):
				content = line.split(e.strip())
				tmp = []
				delimiter = 0
				tmp.append(e.strip())
				for c in content[-1].strip().split():
					tmp.append(c)
				for s in tpm:
					if delimiter < s:
						delimiter = s
				space.append(delimiter)
				transpose.append(tmp)
				break
	
	
	transpose = zip(*transpose)
	for x in transpose:
		for y in range(len(x)):
			#Sabba
			output.write(y+'  ')
		output.write('\n')
	
	#with open(path3+'/report.txt') as f:
	#	input1 = [x.split() for x in f]
	#for x in zip(*input1):
	#	for y in x:
	#		output.write(y,end='')
	#	output.write('\n')
	output.close()

#Main code handler	
for arg in sys.argv:
	if arg.startswith('History'):
		history.append(arg[7:])
	elif arg.startswith('Dataset'):
		data = arg[7:].split(',')
		if data[2] == 'contig':
			contig.append(data[1])
			if data[0] != '':
			   contigLabel.append(data[0])
		else:
			scaffold.append(data[1])
			if data[0] != '':
			   scaffoldLabel.append(data[0])
	elif arg.startswith('dbRef'):
		data = arg[5:].split(':')
		key = data[0].split(',')
		if data[1] == 'None':
			for k in key:
				dbRef.append(refPath+k+'.fna,')
		else:
			for k in key:
				dbRef.append(refPath+k+'.fna,'+genePath+k+'.gff')
		if len(dbRef) > 1: multi = True
	elif arg.startswith('Ref'):
		ref = arg[3:]
		if ref.split(',')[1] == 'True':
			multi = True
	elif arg.startswith('Min'):
		minThreshold = int(arg[3:])
	elif arg.startswith('Max'):
		maxThreshold = int(arg[3:])
	elif arg.startswith('Thr'):
		threads = int(arg[3:])
	else: #path
		path = arg

if len(contig) + len(scaffold) == 0:
	raise ValueError('Provide at least one dataset')
elif (len(contigLabel) != 0) and (len(contigLabel) != len(contig)):
	raise ValueError('Number of labels does not match 0 or the number of datasets with contigs')
elif (len(scaffoldLabel) != 0) and (len(scaffoldLabel) != len(scaffold)):
	raise ValueError('Number of labels does not match 0 or the number of datasets with scaffolds')
elif (minThreshold >= maxThreshold):
	raise ValueError('Threshold minimum cannot be larger than threshold maximum %d vs %d' % (minThreshold, maxThreshold))
elif ((len(contig)+len(scaffold)) > 1) & ((len(dbRef) > 1) | multi):
	raise ValueError('Cannot have multiple datasets and reference genomes\n \
	Choose either one dataset with multiple reference genomes or\n \
	one reference genome with multiple datasets')
else: #Validation complete
	#Compute quality assessment
	#Make directories for all solutions
	os.system('mkdir '+path)
		
	if ((len(dbRef) < 2) & (not multi)):
		reference = ''
		gene = ''
		if len(ref) != 0:
			tmpRef = ref.split(',')
			reference = tmpRef[0]
			if tmpRef[2] != 'None':
				gene = tmpRef[2]
		elif len(dbRef) != 0:
			data = dbRef[0].split(',')
			reference = data[0]
			gene = data[1]
		if len(contig) != 0:
			resultPath = path+'/Contig'
			runCommand(resultPath, reference, gene, contigLabel, contig, False)
		if len(scaffold) != 0:
			resultPath = path+'/Scaffold'
			runCommand(resultPath, reference, gene, scaffoldLabel, scaffold, True)
		if (len(contig) != 0) & (len(scaffold) != 0):
			if (len(contigLabel)+len(scaffoldLabel)) == (len(contig)+len(scaffold)):
				runCommand(path+'/combined_dataset', reference, gene, contigLabel+scaffoldLabel, contig+scaffold, False)
			else:
				runCommand(path+'/combined_dataset', reference, gene, '', contig+scaffold, False)	
	else:
		data = []
		scaff = False
		if len(contig) != 0:
			data.append(contigLabel)
			data.append(contig)
		else:
			data.append(scaffoldLabel)
			data.append(scaffold)
			scaff = True
		if len(dbRef) != 0:
			for r in dbRef:
				reference = r.split(',')
				runCommand(path+'/'+reference[0].split('/')[-1][:-4], reference[0], reference[1], data[0], data[1], scaff)
			os.system('mkdir '+path+'/combined_reference')
			os.system('cp -rf '+path+'/B_cereus_ATCC_1098/report_html_aux '+path+'/combined_reference')
			os.system('cp '+path+'/B_cereus_ATCC_1098/*report* '+path+'/combined_reference')
                        #os.system('mkdir '+path3+'/json')
			os.system('cp -rf '+path+'/B_cereus_ATCC_1098/json '+path+'/combined_reference')
			for i in range(1,len(dbRef)):
				if i == 1:
					combineResult(path+'/'+dbRef[0].split(',')[0].split('/')[-1][:-4], path+'/'+dbRef[1].split(',')[0].split('/')[-1][:-4], path+'/combined_reference', False)
				else:
					combineResult(path+'/combined_reference', path+'/'+dbRef[i].split(',')[0].split('/')[-1][:-4], path+'/combined_reference', True)
		elif len(ref) != 0:
			reference = ref.split(',')
			refSplit = []
			gene = ''
			with open(reference[0]) as r:
				content = r.read()
				refSplit = content.split('>')
			if reference[2] != 'None':
				with open(reference[2]) as r:
					content = r.read()
					gene = content.split('###')
				for i in range(len(refSplit)):
					tmpRef = open(path+'/tmpRef.fna','w')
					tmpRef.write('>'+refSplit[i])
					tmpRef.close()
					tmpGene = open(path+'/tmpGene.gff','w')
					tmpGene.write(gene[i]+'###')
					tmpGene.close()
					for h in heading:
						if h.startswith('NC_'):
							runCommand(path+'/'+h, path+'/tmpRef.fna', path+'/tmpGene.gff', data[0], data[1], scaff)
							break
					os.system('rm '+path+'/tmpRef.fna '+path+'/tmpGene.gff')
			else:
				for i in range(len(refSplit)):
					tmpRef = open(path+'/tmpRef.fna','w')
					tmpRef.write('>'+refSplit[i])
					tmpRef.close()
					heading = refSplit[i].split('\n')[0].split('|')
					for h in heading:
						if h.startswith('NC_'):
							runCommand(path+'/'+h, path+'/tmpRef.fna', '', data[0], data[1], scaff)
							break
					os.system('rm '+path+'/tmpRef.fna')
	writeHtmlFile(path)
